{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_3mers_df = pd.read_csv('encoded_data/test_3mers.csv',index_col=[0])\n",
    "test_4mers_df = pd.read_csv('encoded_data/test_4mers.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = test_3mers_df.iloc[:, :-2]\n",
    "# y_test = test_3mers_df['group']\n",
    "X_test = test_4mers_df.iloc[:, :-2]\n",
    "y_test = test_4mers_df['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "performance_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Path to the directory containing the models\n",
    "model_directory = \"WGS_models/\"\n",
    "\n",
    "# Load and evaluate each model\n",
    "for model_file in os.listdir(model_directory):\n",
    "    if '_4mers' in model_file:  # Ensure the file is a joblib file\n",
    "        model_path = os.path.join(model_directory, model_file)\n",
    "        model = load(model_path)\n",
    "        model_name = model_file.split('.')[0]  # Get model name from file name\n",
    "\n",
    "        # Predicting using the loaded model\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculating performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Create a temporary DataFrame for the current model and concatenate it\n",
    "        temp_df = pd.DataFrame({\n",
    "            'Model': [model_name],\n",
    "            'Accuracy': [accuracy],\n",
    "            'Precision': [precision],\n",
    "            'Recall': [recall],\n",
    "            'F1 Score': [f1]\n",
    "        })\n",
    "        performance_df = pd.concat([performance_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.868376</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.868376</td>\n",
       "      <td>0.868036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaussian_naive_bayes</td>\n",
       "      <td>0.675524</td>\n",
       "      <td>0.677122</td>\n",
       "      <td>0.675524</td>\n",
       "      <td>0.676311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.902875</td>\n",
       "      <td>0.901278</td>\n",
       "      <td>0.902875</td>\n",
       "      <td>0.901179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.749495</td>\n",
       "      <td>0.748497</td>\n",
       "      <td>0.749495</td>\n",
       "      <td>0.679272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.832830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.913598</td>\n",
       "      <td>0.912472</td>\n",
       "      <td>0.913598</td>\n",
       "      <td>0.912680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.835742</td>\n",
       "      <td>0.829885</td>\n",
       "      <td>0.835742</td>\n",
       "      <td>0.827745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall  F1 Score\n",
       "0         decision_tree  0.868376   0.867736  0.868376  0.868036\n",
       "1  gaussian_naive_bayes  0.675524   0.677122  0.675524  0.676311\n",
       "2                   knn  0.902875   0.901278  0.902875  0.901179\n",
       "3   logistic_regression  0.749495   0.748497  0.749495  0.679272\n",
       "4                   svm  0.841492   0.836774  0.841492  0.832830\n",
       "5         random_forest  0.913598   0.912472  0.913598  0.912680\n",
       "6               xgboost  0.835742   0.829885  0.835742  0.827745"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_4mers</td>\n",
       "      <td>0.859363</td>\n",
       "      <td>0.855414</td>\n",
       "      <td>0.859363</td>\n",
       "      <td>0.854849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost_4mers</td>\n",
       "      <td>0.845688</td>\n",
       "      <td>0.840809</td>\n",
       "      <td>0.845688</td>\n",
       "      <td>0.838835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn_4mers</td>\n",
       "      <td>0.906915</td>\n",
       "      <td>0.905470</td>\n",
       "      <td>0.906915</td>\n",
       "      <td>0.905426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression_4mers</td>\n",
       "      <td>0.743434</td>\n",
       "      <td>0.761869</td>\n",
       "      <td>0.743434</td>\n",
       "      <td>0.658056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_forest_4mers</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.911313</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.911594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decision_tree_4mers</td>\n",
       "      <td>0.873038</td>\n",
       "      <td>0.873196</td>\n",
       "      <td>0.873038</td>\n",
       "      <td>0.873116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gaussian_naive_bayes_4mers</td>\n",
       "      <td>0.679409</td>\n",
       "      <td>0.680819</td>\n",
       "      <td>0.679409</td>\n",
       "      <td>0.680104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy  Precision    Recall  F1 Score\n",
       "0                   svm_4mers  0.859363   0.855414  0.859363  0.854849\n",
       "1               xgboost_4mers  0.845688   0.840809  0.845688  0.838835\n",
       "2                   knn_4mers  0.906915   0.905470  0.906915  0.905426\n",
       "3   logistic_regression_4mers  0.743434   0.761869  0.743434  0.658056\n",
       "4         random_forest_4mers  0.912354   0.911313  0.912354  0.911594\n",
       "5         decision_tree_4mers  0.873038   0.873196  0.873038  0.873116\n",
       "6  gaussian_naive_bayes_4mers  0.679409   0.680819  0.679409  0.680104"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def encode_sequence(sequence, k):\n",
    "    all_kmers = [''.join(p) for p in product('ATCG', repeat=k)]\n",
    "    kmer_counts = {kmer: 0 for kmer in all_kmers}\n",
    "    sequence = ''.join(char for char in sequence if char in ['A', 'T', 'C', 'G'])\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        kmer = sequence[i:i+k]\n",
    "        if kmer in kmer_counts:\n",
    "            kmer_counts[kmer] += 1\n",
    "    encoded_df = pd.DataFrame([kmer_counts.values()], columns=all_kmers)\n",
    "    sum_counts = encoded_df.sum(axis=1)\n",
    "    encoded_df = encoded_df.divide(sum_counts, axis=0)\n",
    "    encoded_df = encoded_df.fillna(0)\n",
    "    return encoded_df\n",
    "\n",
    "\n",
    "def read_fasta_to_kmers(file_path, k_mers):\n",
    "    dfs_per_sequence = []\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        sequence = str(record.seq)\n",
    "        encoded_sequence_dfs = [encode_sequence(sequence, k) for k in k_mers]\n",
    "        merged_sequence_df = pd.concat(encoded_sequence_dfs, axis=1)\n",
    "        merged_sequence_df['filename_x'] = file_path\n",
    "        dfs_per_sequence.append(merged_sequence_df)\n",
    "    final_df = pd.concat(dfs_per_sequence, ignore_index=True)\n",
    "    final_df = final_df.fillna(0)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_patho_df = read_fasta_to_kmers('../MAG/MAG_Pathogen.fna',[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_patho_df['group'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_non_patho_df = read_fasta_to_kmers('../MAG/MAG_NonPathogen.fna',[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_non_patho_df['group'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_df = pd.concat([mag_patho_df,mag_non_patho_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = mag_df.iloc[:, :-2]\n",
    "y_test = mag_df['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Path to the directory containing the models\n",
    "model_directory = \"WGS_models/\"\n",
    "\n",
    "# Load and evaluate each model\n",
    "for model_file in os.listdir(model_directory):\n",
    "    if '_4mers' not in model_file:  # Ensure the file is a joblib file\n",
    "        model_path = os.path.join(model_directory, model_file)\n",
    "        model = load(model_path)\n",
    "        model_name = model_file.split('.')[0]  # Get model name from file name\n",
    "\n",
    "        # Predicting using the loaded model\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculating performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Create a temporary DataFrame for the current model and concatenate it\n",
    "        temp_df = pd.DataFrame({\n",
    "            'Model': [model_name],\n",
    "            'Accuracy': [accuracy],\n",
    "            'Precision': [precision],\n",
    "            'Recall': [recall],\n",
    "            'F1 Score': [f1]\n",
    "        })\n",
    "        performance_df = pd.concat([performance_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.729483</td>\n",
       "      <td>0.814922</td>\n",
       "      <td>0.729483</td>\n",
       "      <td>0.751661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaussian_naive_bayes</td>\n",
       "      <td>0.437690</td>\n",
       "      <td>0.736746</td>\n",
       "      <td>0.437690</td>\n",
       "      <td>0.461832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.782675</td>\n",
       "      <td>0.848930</td>\n",
       "      <td>0.782675</td>\n",
       "      <td>0.799237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.215805</td>\n",
       "      <td>0.831703</td>\n",
       "      <td>0.215805</td>\n",
       "      <td>0.078759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.586626</td>\n",
       "      <td>0.737981</td>\n",
       "      <td>0.586626</td>\n",
       "      <td>0.623654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.860182</td>\n",
       "      <td>0.886265</td>\n",
       "      <td>0.860182</td>\n",
       "      <td>0.867364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.471125</td>\n",
       "      <td>0.771562</td>\n",
       "      <td>0.471125</td>\n",
       "      <td>0.496371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall  F1 Score\n",
       "0         decision_tree  0.729483   0.814922  0.729483  0.751661\n",
       "1  gaussian_naive_bayes  0.437690   0.736746  0.437690  0.461832\n",
       "2                   knn  0.782675   0.848930  0.782675  0.799237\n",
       "3   logistic_regression  0.215805   0.831703  0.215805  0.078759\n",
       "4                   svm  0.586626   0.737981  0.586626  0.623654\n",
       "5         random_forest  0.860182   0.886265  0.860182  0.867364\n",
       "6               xgboost  0.471125   0.771562  0.471125  0.496371"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
